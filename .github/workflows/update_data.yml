name: Update CSVs daily

on:
  schedule:
    # Horario de invierno (CET): 22:00 Espa√±a = 21:00 UTC
    - cron: "0 21 * * 1-5"
    # Horario de verano (CEST): 22:00 Espa√±a = 20:00 UTC  
    - cron: "0 20 * * 1-5"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install yfinance pandas requests lxml html5lib

      - name: Create update script
        run: |
          cat > update_csv.py << 'EOF'
          import yfinance as yf
          import pandas as pd
          import os
          import glob
          from datetime import datetime, timedelta
          
          def get_existing_tickers():
              """Obtiene solo los tickers que existen en la carpeta data/"""
              csv_files = glob.glob("data/*.csv")
              tickers = []
              for file_path in csv_files:
                  filename = os.path.basename(file_path)
                  if filename.endswith('.csv'):
                      ticker = filename.replace('.csv', '')
                      tickers.append(ticker)
              return sorted(list(set(tickers)))
          
          def update_ticker_data(ticker):
              """Actualiza datos de un ticker espec√≠fico"""
              try:
                  filename = f"data/{ticker}.csv"
                  
                  # Verificar que el archivo existe
                  if not os.path.exists(filename):
                      print(f"‚ùå {ticker}: Archivo no encontrado")
                      return False
                  
                  # Leer el archivo existente
                  df = pd.read_csv(filename, index_col="Date", parse_dates=True)
                  
                  # Si el DataFrame no est√° vac√≠o
                  if len(df) > 0:
                      last_date = df.index[-1]
                      today = datetime.now().date()
                      
                      # Si ya est√° actualizado (√∫ltimos 3 d√≠as), no hacer nada
                      if last_date.date() >= (today - timedelta(days=3)):
                          print(f"‚úÖ {ticker}: Ya actualizado hasta {last_date.date()}")
                          return True
                      
                      # Descargar datos desde la √∫ltima fecha
                      start_date = last_date - timedelta(days=7)  # Margen de seguridad
                      end_date = today + timedelta(days=1)
                      
                      new_data = yf.download(ticker, start=start_date, end=end_date)
                      if not new_data.empty and len(new_data) > 0:
                          # Asegurar formato de √≠ndice
                          new_data.index = pd.to_datetime(new_data.index)
                          
                          # Combinar datos
                          combined = pd.concat([df, new_data])
                          combined = combined[~combined.index.duplicated(keep='last')].sort_index()
                          combined.to_csv(filename)
                          print(f"üîÑ {ticker}: Actualizado hasta {combined.index[-1].date()}")
                          return True
                      else:
                          print(f"‚ö†Ô∏è {ticker}: No hay nuevos datos disponibles")
                          return True
                  else:
                      # Archivo vac√≠o, descargar historial
                      print(f"üì• {ticker}: Archivo vac√≠o, descargando historial...")
                      data = yf.download(ticker, period="max")
                      if not data.empty:
                          data.to_csv(filename)
                          print(f"üíæ {ticker}: Historial guardado")
                          return True
                      else:
                          print(f"‚ùå {ticker}: No se pudo descargar historial")
                          return False
                          
              except Exception as e:
                  print(f"‚ùå {ticker}: Error - {e}")
                  return False
              return False
          
          if __name__ == "__main__":
              print("=== Actualizaci√≥n de Datos Diaria ===")
              
              # Solo actualizar los tickers que existen en la carpeta data/
              tickers = get_existing_tickers()
              print(f"Encontrados {len(tickers)} archivos CSV para actualizar")
              print(f"Tickers: {', '.join(tickers[:10])}{'...' if len(tickers) > 10 else ''}")
              
              # Asegurar que SPY y QQQ est√©n incluidos si existen
              important_tickers = ['SPY', 'QQQ']
              for important in important_tickers:
                  if important in tickers:
                      print(f"üéØ Prioritario: {important}")
              
              print(f"\nActualizando {len(tickers)} tickers...")
              updated = 0
              errors = 0
              
              for i, ticker in enumerate(tickers, 1):
                  print(f"[{i}/{len(tickers)}] {ticker}")
                  if update_ticker_data(ticker):
                      updated += 1
                  else:
                      errors += 1
              
              print(f"\n=== Resumen ===")
              print(f"‚úÖ Actualizados: {updated}")
              print(f"‚ùå Errores: {errors}")
              print(f"üìä Total procesados: {len(tickers)}")
          EOF

      - name: Run update script
        run: python update_csv.py

      - name: Commit and push changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add data/*.csv
          git diff --staged --quiet || (git commit -m "Auto-update CSVs ($(date -u +'%Y-%m-%d %H:%M:%S'))" && git push) || echo "No changes to commit or push failed"
